\chapter{Аналитическая часть}
В данном разделе описаны определение словаря как структуры данных, а также алгоритмы поиска по словарю.

\section{Словарь как структура данных}

Словарь (или ''\textit{ассоциативный массив}'') \cite{dict} - абстрактный тип данных (интерфейс к хранилищу данных), позволяющий хранить пары вида «(ключ, значение)» и поддерживающий операции добавления пары, а также поиска и удаления пары по ключу:
\begin{itemize}
	\item \texttt{INSERT(k, v)};
	\item \texttt{FIND(k)};
	\item \texttt{REMOVE(k)}.
\end{itemize}

В паре \texttt{(k, v)}: \texttt{v} называется значением, ассоциированным с ключом \texttt{k}. Где \texttt{k} — это ключ, a \texttt{v} — значение. Семантика и названия вышеупомянутых операций в разных реализациях ассоциативного массива могут отличаться.

Операция \texttt{ПОИСК(k)} возвращает значение, ассоциированное с заданным ключом, или некоторый специальный объект \texttt{НЕ\_НАЙДЕНО}, означающий, что значения, ассоциированного с заданным ключом, нет. Две другие операции ничего не возвращают (за исключением, возможно, информации о том, успешно ли была выполнена данная операция).

Ассоциативный массив с точки зрения интерфейса удобно рассматривать как обычный массив, в котором в качестве индексов можно использовать не только целые числа, но и значения других типов — например, строки.

В данной лабораторной работе в качестве ключа будет использоваться строка: название города, а в качестве значения -- строка: страна, в которой расположен город.

\section{Алгоритм полного перебора}
Алгоритмом полного перебора \cite{AI} называют метод решения задачи, при котором по очереди рассматриваются все возможные варианты. В случае реализации алгоритма в рамках данной работы будут последовательно перебираться ключи словаря до тех пор, пока не будет найден нужный. 

Трудоёмкость алгоритма зависит от того, присутствует ли искомый ключ в словаре, и, если присутствует -- насколько он далеко от начала массива ключей.

Пусть на старте алгоритм затрагивает $k_{0}$ операций, а при сравнении $k_{1}$ операций. 

Пусть алгоритм нашёл элемент на первом сравнении (лучший случай), тогда будет затрачено $k_0 + k_1$ операций, на втором - $k_0 + 2 \cdot k_1$, на последнем (худший случай) - $k_0 + N \cdot k_1$. Если ключа нет в массиве ключей, то мы сможем понять это, только перебрав все ключи, таким образом трудоёмкость такого случая равно трудоёмкости случая с ключом на последней позиции. Средняя трудоёмкость может быть рассчитана как математическое ожидание по формуле (\ref{for:brute}), где $\Omega$ -- множество всех возможных случаев.

\begin{equation}
\label{for:brute}
\begin{aligned}
\sum\limits_{i \in \Omega} p_i \cdot f_i = & (k_0 + k_1) \cdot \frac{1}{N + 1} + (k_0 + 2 \cdot k_1) \cdot \frac{1}{N+1} +\\& + (k_0 + 3 \cdot k_1) \cdot \frac{1}{N + 1} + (k_0 + Nk_1)\frac{1}{N + 1} + (k_0 + N \cdot k_1) \cdot \frac{1}{N + 1} =\\& = k_0\frac{N+1}{N+1}+k_1+\frac{1 + 2 + \cdots + N + N}{N + 1} = \\& = k_0 + k_1 \cdot \left(\frac{N}{N + 1} + \frac{N}{2}\right) = k_0 + k_1 \cdot \left(1 + \frac{N}{2} - \frac{1}{N + 1}\right)
\end{aligned}
\end{equation}

\section{Алгоритм поиска в упорядоченном словаре двоичным поиском}
Бинарный поиск базируется на том, что словарь изначально отсортирован, что позволяет сравнивать ключ с средним элементом, и, если, он меньше, то продолжать искать в левой части, таким же методом, иначе в правой.

Таким образом, при двоичном поиске \cite{binary} обход можно представить деревом, поэтому трудоёмкость в худшем случае составит $k_{0} + \log_2 N$ (в худшем случае нужно спуститься по двоичному дереву от корня до листа).

Лучшим случаем будет случай, если искомый ключ окажется средним элементом, тогда трудоемкость будет равна $k_{0} + \log_2 1$.

Скорость роста функции $\log_2 N$ меньше, чем скорость линейной функции, полученной для полного перебора.

\section{Поиск с помощью сегментов}
Алгоритм на вход получает словарь. Далее словарь разбивается на сегменты так, что все элементы с некоторым общим признаком попадают в один сегмент (для букв это может быть первая буква, для чисел - остаток от деления).

Сегменты упорядочиваются по значению частотной характеристики так, чтобы к элементам с наибольшей частотной характеристикой был самый быстрый доступ.
Например, такой характеристикой может быть размер сегмента.

Вероятность обращения к определенному сегменту равна сумме вероятностей обращений к его ключам, то есть $P_i = \sum_{j}p_j = N \cdot p$, где $P_i$ -- вероятность обращения к $i$-ому сегменту, $p_j$ - вероятность обращения к $j$-ому элементу, который принадлежит $i$-ому сегменту. 

Если обращения ко всем ключам равновероятны, то можно заменить сумму на произведение, где $N$ - количество элементов в $i$-ом сегменте, а $p$ - вероятность обращения к произвольному ключу.

Далее ключи в каждом сегменте сортируются для того, чтобы внутри каждого сегмента можно было использовать бинарный поиск, который обеспечит эффективный поиск со сложностью $O(\log_2 m)$ (где $m$ - количество ключей в сегменте) внутри сегмента.

Таким образом, сначала выбирается нужный сегмент, а затем в нем проводится бинарный поиск нужного элемента.

Средняя трудоёмкость при множестве всех возможных случаев $\Omega$ может быть рассчитана по формуле (\ref{for:anal}). 

\begin{equation}
\label{for:anal}
\sum_{i \in \Omega}{\left(f_{\text{выбор сегмента i-ого элемента}} + f_{\text{бинарный поиск i-ого элемента}}\right)} \cdot p_i
\end{equation}

Худший случай -- это случай, когда выбор сегмента -- $N \cdot p_i$, при этом $N$ равно числу сегментов. А поиск элемента (ключа) в данном сегменте -- $\log_2 N$, где $N$ -- число элементов в сегменте.

Лучший случай -- если искомый сегмент оказывается первым, и в этом сегменте исходный ключ -- серединный элемент, так как бинарный поиск сначала укажет в середину. 

\section{Вывод}
В данном разделе был рассмотрен абстрактный тип данных словарь и возможные реализации алгоритмов поиска в нём.
